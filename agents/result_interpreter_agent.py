import os
import json
from openai import OpenAI
from dotenv import load_dotenv
import numpy as np

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
openai = OpenAI()


def format_interpretation_prompt(
    test_type: str,
    dataset_summary: dict,
    test_info: dict,
    result: dict
) -> list:
    """
    Builds a system/user prompt for result interpretation by LLM.  maybe change to be more general to other tests
    """

    system_prompt = """
    You are a scientific writing assistant.

    You receive:
    - A summary of a dataset
    - A type of statistical or machine learning analysis that was performed
    - The goal or question that the analysis was trying to answer
    - The numeric or textual result of the analysis

    Your task is to write a brief, clear explanation in academic style (1–3 paragraphs) that:
    - Describes what was tested and why
    - Interprets the results (e.g., p-value, correlation coefficient, accuracy, effect size)
    - Answers the original question
    - Is appropriate for use in a thesis, research paper, or technical report
    - Mentions any limitations or follow-ups if obvious

    Use formal, concise language. Avoid markdown or code formatting.
    Respond with plain text only.
    """

    # Format the post-hoc (if present)
    post_hoc_text = ""
    if result.get("post_hoc"):
        post_hoc_text = f"\n\nPost-hoc analysis (Tukey HSD):\n{result['post_hoc']}"

    user_prompt = f"""
    Dataset summary:
    {dataset_summary.get("explanation", "N/A")}

    Type of analysis: {test_type}

    Question being answered:
    {test_info.get("question", "N/A")}

    Test details:
    {json.dumps(test_info, indent=2)}

    Result:
    {json.dumps(result, indent=2)}{post_hoc_text}
    """

    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]


def interpret_test_result(
    test_type: str,
    dataset_summary: dict,
    test_info: dict,
    result: dict
) -> dict:
    """
    Uses GPT-4o to generate a scientific explanation of an analysis result.
    Adds explanation into result["text"] and returns the whole result dict.
    """

    print(f"[Interpret Test] type: {test_type}")
    print(f"[Test Info]: {test_info}")
    print(f"[Raw Result]: {result}")

    messages = format_interpretation_prompt(
        test_type=test_type,
        dataset_summary=dataset_summary,
        test_info=test_info,
        result=result
    )

    response = openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages
    )

    explanation = response.choices[0].message.content.strip()

    # Inject explanation into the result dict
    result["text"] = explanation
    return result


def safe_json(obj): # aux func to avoid not serializable errors
    if isinstance(obj, (np.integer, np.int64)): return int(obj)
    if isinstance(obj, (np.floating, np.float64)): return float(obj)
    if isinstance(obj, (np.ndarray,)): return obj.tolist()
    if isinstance(obj, (np.bool_)): return bool(obj)
    if pd.isna(obj): return None
    return str(obj)


def interpret_variable_summary(result: dict) -> dict:
    """
    Generates a plain-text, human-readable summary of variable-level statistics 
    using a language model. This is intended for descriptive summaries rather than 
    hypothesis testing.

    Args:
        result (dict): A dictionary containing per-variable statistics, typically 
                       generated by `summarize_variable_statistics`. It includes 
                       fields like 'mean', 'std', 'missing', or category counts 
                       depending on the variable type.

    Returns:
        dict: The original result dictionary with an additional 'text' field 
              containing a natural language summary of the variable statistics.
    """

    if not isinstance(result, dict):
        return {
            "error": "Invalid input to interpreter: expected a dictionary of variable statistics.",
            "text": "Unable to summarize variable statistics due to internal format error."
        }

    system_prompt = """
    You are a data analyst assistant.

    You will be given:
    - A high-level dataset summary
    - A structured dictionary of variable-level statistics (mean, std, counts)

    Your task is to write a clear, concise summary (1–2 paragraphs) that:
    - Describes the overall composition of the dataset
    - Highlights key quantitative variables and their typical ranges
    - Comments on the most frequent categories for categorical variables
    - Avoids listing every value — focus on the big picture
    - Avoids markdown and code formatting

    Output should be suitable for use in a technical report or exploratory data analysis summary.
    """

    user_prompt = f"""
    Variable-level statistics:
    {json.dumps(result, indent=2, default=safe_json)}
    """

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]

    try:
        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages
        )
        explanation = response.choices[0].message.content.strip()
        result["text"] = explanation
        return result
    except Exception as e:
        return {
            "error": f"Failed to generate summary: {str(e)}",
            "text": "Unable to generate summary due to an internal error."
        }
